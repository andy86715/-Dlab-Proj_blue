{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\弘林\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file C:\\Users\\弘林\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[閒聊]\n",
      " 室友在哭\n",
      "[陰天]\n",
      " 擱淺的人\n",
      "[閒聊]\n",
      " 想睡的人叫不醒。\n",
      "[陰天]\n",
      " 躊躇\n",
      "[陰天]\n",
      " 沒有了\n",
      "[陰天]\n",
      " 加油\n",
      "[晴天]\n",
      " 閱讀能力\n",
      "[陰天]\n",
      " 工作\n",
      "[陰天]\n",
      " 老娘就是不想跑步\n",
      "[晴天]\n",
      " 約跑\n",
      "[晴天]\n",
      "今天跑35.19km 好累好嗨 我轉移陣地了 \n",
      "［陰天］失去了自我]\n",
      "[陰天]\n",
      " 我很害怕(雷\n",
      "[閒聊]\n",
      " \n",
      "[陰天]\n",
      " 我累了（雷）\n",
      "[陰天]\n",
      " 巨大的寂寞\n",
      "[陰天]\n",
      " 發現自己原來沒談話對象\n",
      "[閒聊]\n",
      " 織圍巾\n",
      "[陰天]\n",
      " 還是會難過....\n",
      "[陰天]\n",
      " 想找個人哭一場\n",
      "[陰天]\n",
      " 失望了\n",
      "Re: [陰天]\n",
      " 過年不想回家怎辦?\n",
      "[陰天]\n",
      " \n",
      "[陰天]\n",
      " 思想清明\n",
      "[陰天]\n",
      " 強制關機\n",
      "[陰天]\n",
      " 覺得\n",
      "[陰天]\n",
      " 討厭被同情\n",
      "[陰天]\n",
      " 強烈地不想去公司\n",
      "[陰天]\n",
      " 原點\n",
      "[陰天]\n",
      " 161220\n",
      "[陰天]\n",
      " 群組\n",
      "[陰天]\n",
      " \n",
      "[陰天]\n",
      " 在上班時間崩潰了。（雷）\n",
      "[閒聊]\n",
      " Be faithful\n",
      "[陰天]\n",
      " 我是懦弱的人\n",
      "[陰天]\n",
      " 反訴理由狀= =\n",
      "[陰天]\n",
      " 送給了他\n",
      "[陰天]\n",
      " 雷\n",
      "[晴天]\n",
      " Lucky day\n",
      "[陰天]\n",
      " 討厭隨便做出的承諾\n",
      "[閒聊]\n",
      "求職障礙，還沒恢復\n",
      "[陰天]\n",
      " 雷/崩塌\n",
      "[陰天]\n",
      " 工作\n",
      "[陰天]\n",
      " 你把我灌醉（微雷）\n",
      "[晴天]\n",
      " 進度\n",
      "[陰天]\n",
      " 良藥亦毒酒\n",
      "[閒聊]\n",
      " 現在不了\n",
      "[陰天]\n",
      " 各種不被理解(雷了\n",
      "[經驗]\n",
      " 食衣住行育樂 (勉勵) \n",
      "[閒聊]\n",
      " 一年了\n",
      "[陰天]\n",
      " 在期末的前一個月爆炸\n",
      "[陰天]\n",
      " 無法掌握自己的人生\n",
      "[閒聊]\n",
      " 醒了一夜\n",
      "[閒聊]\n",
      " 微微雷\n",
      "[陰天]\n",
      " \n",
      "[陰天]\n",
      " 睡不著 只能躲在床上發呆\n",
      "[陰天]\n",
      "雷！！！！！！！\n",
      "[陰天]\n",
      "  總是貪心的\n",
      "Re: [閒聊]\n",
      " 送新年卡片~\n",
      "[陰天]\n",
      " 雷.\n",
      "[閒聊]\n",
      " 咖啡戒斷\n",
      "[閒聊]\n",
      " 凡是你排斥的，就是你所要學習的\n",
      "[陰天]\n",
      " Anxiety\n",
      "[陰天]\n",
      " 無助（微雷）\n",
      "[晴天]\n",
      " 暖冬\n",
      "[陰天]\n",
      " 恐懼(雷)\n",
      "[陰天]\n",
      " 其實原本是晴天\n",
      "[陰天]\n",
      " 雷\n",
      "[陰天]\n",
      " 自作多情的遺棄感\n",
      "[閒聊]\n",
      " 心理學的書\n",
      "[閒聊]\n",
      " \n",
      "[陰天]\n",
      " 多雲時晴\n",
      "[陰天]\n",
      "\n",
      "[陰天]\n",
      " 沒有後路\n",
      "[晴天]\n",
      " 離\n",
      "[陰天]\n",
      " 抗拒\n",
      "[陰天]\n",
      " 下雨天\n",
      "[陰天]\n",
      " 反~訴~狀~(有專業術語不是賣弄不好意思\n",
      "[陰天]\n",
      " 煩\n",
      "[陰天]\n",
      " 發燒\n",
      "None\n",
      "nagnukiy (冠)\n",
      "db12467 (miumiu)\n",
      "hesione (我離開我自己)\n",
      "burgergirl (20 seconds insane)\n",
      "burgergirl (20 seconds insane)\n",
      "sheepinair (綿羊在空中)\n",
      "DavidJam (平安又有錢才是福)\n",
      "llltwilight (llltwilight)\n",
      "imyuya (夜灰)\n",
      "ej01019 (真正)\n",
      "kazusn ()\n",
      "xuxnes (迷路的羔羊)\n",
      "k09090806 (JY)\n",
      "yukilala (水藍色)\n",
      "wearesad5566 (我難過)\n",
      "lyviasun (:))\n",
      "zeze (三月うさぎ)\n",
      "Yinsin (少女心大叔)\n",
      "px37521 (.....)\n",
      "louis10452 (秋天的楓)\n",
      "zh010919 (Ashliy)\n",
      "alfven (馮小丸)\n",
      "FlyFuta (想做啥就做啥的腐太)\n",
      "burgergirl (20 seconds insane)\n",
      "nagnukiy (冠)\n",
      "qqqlisa (兔子蹦蹦跳跳)\n",
      "xiaoshar (煞煞)\n",
      "ilegenes (ilegenes)\n",
      "piecemind (piecemind)\n",
      "hunter10 (觀察自己)\n",
      "sheepinair (綿羊在空中)\n",
      "lyviasun (:))\n",
      "squen (咪花恰的媽)\n",
      "agnme2 (基督是我滿足)\n",
      "zeze (三月うさぎ)\n",
      "k09090806 (JY)\n",
      "DavidJam (平安又有錢才是福)\n",
      "teapa (為什麼突然就不見)\n",
      "babe18 (love國光E姊蘇心甯)\n",
      "yanbol2001 (紫硯)\n",
      "feynmanx (Westworld Arnold)\n",
      "lydiahsieh (Lydia)\n",
      "lyviasun (:))\n",
      "flying1618 (六年)\n",
      "ej01019 (真正)\n",
      "UntermRad (黃色檸檬樹)\n",
      "ej01019 (真正)\n",
      "zh010919 (Ashliy)\n",
      "caregirl (生活簡單知足)\n",
      "kid3875215 (銘哥)\n",
      "FlyFuta (想做啥就做啥的腐太)\n",
      "nagnukiy (冠)\n",
      "teapa (為什麼突然就不見)\n",
      "lamort (跳舞的死神)\n",
      "hesione (我離開我自己)\n",
      "andyex0734 (雷斯林的孤獨)\n",
      "teapa (為什麼突然就不見)\n",
      "DavidJam (平安又有錢才是福)\n",
      "ej01019 (真正)\n",
      "asthedew (婭)\n",
      "bartwang (利禦寇)\n",
      "Annydodo (。單純是種快樂。)\n",
      "rosalic0423 (流緒)\n",
      "flying1618 (六年)\n",
      "babe18 (love國光E姊蘇心甯)\n",
      "ui5550 (Shie)\n",
      "blueskymaple (大谷翔平我老公)\n",
      "tearsoffish (魚的眼淚)\n",
      "ahliz (半糖草莓醬)\n",
      "feynmanx (Westworld Arnold)\n",
      "lamort (跳舞的死神)\n",
      "fuye12 (fuye)\n",
      "nalina (★Nalina乖)\n",
      "DarkGray2 (灰)\n",
      "qqqlisa (兔子蹦蹦跳跳)\n",
      "ilegenes (ilegenes)\n",
      "gossiplarry (賴瑞)\n",
      "k09090806 (JY)\n",
      "DavidJam (平安又有錢才是福)\n",
      "lemonish98 (草萱)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "a = 1661\n",
    "b = 1665\n",
    "\n",
    "def get_title():\n",
    "    for i in range(a,b):\n",
    "        res = requests.get(\"https://www.ptt.cc/bbs/prozac/index\"+str(i)+\".html\")\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        for website in soup.select(\".r-ent\"):\n",
    "            try:    \n",
    "                res2 = requests.get('https://www.ptt.cc/'+website(\"a\")[0]['href'])\n",
    "                soup2 = BeautifulSoup(res2.text)\n",
    "                if \"資訊\" in (soup2.select(\".article-meta-value\")[2].text):\n",
    "                    pass\n",
    "                else:\n",
    "                    c = soup2.select(\".article-meta-value\")[2].text\n",
    "                    d = c.split(\"]\")\n",
    "#                     標題分類\n",
    "                    print(d[0]+\"]\")\n",
    "#                     標題內容\n",
    "                    print(d[1])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def get_author():\n",
    "    for i in range(a,b):\n",
    "        res = requests.get(\"https://www.ptt.cc/bbs/prozac/index\"+str(i)+\".html\")\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        for website in soup.select(\".r-ent\"):\n",
    "            try:    \n",
    "                res2 = requests.get('https://www.ptt.cc/'+website(\"a\")[0]['href'])\n",
    "                soup2 = BeautifulSoup(res2.text)\n",
    "                if \"資訊\" in (soup2.select(\".article-meta-value\")[2].text):\n",
    "                    pass\n",
    "                else:\n",
    "                    print(soup2.select(\".article-meta-value\")[0].text)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def get_time():\n",
    "    for i in range(a,b):\n",
    "        res = requests.get(\"https://www.ptt.cc/bbs/prozac/index\"+str(i)+\".html\")\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        for website in soup.select(\".r-ent\"):\n",
    "            try:    \n",
    "                res2 = requests.get('https://www.ptt.cc/'+website(\"a\")[0]['href'])\n",
    "                soup2 = BeautifulSoup(res2.text)\n",
    "                if \"資訊\" in (soup2.select(\".article-meta-value\")[2].text):\n",
    "                    pass\n",
    "                else:\n",
    "                    print(soup2.select(\".article-meta-value\")[3].text)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def get_content():\n",
    "    for i in range(a,b):\n",
    "        res = requests.get(\"https://www.ptt.cc/bbs/prozac/index\"+str(i)+\".html\")\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        for website in soup.select(\".r-ent\"):\n",
    "            try:\n",
    "                res2 = requests.get('https://www.ptt.cc/'+website(\"a\")[0]['href'])\n",
    "                soup2 = BeautifulSoup(res2.text)\n",
    "                if \"資訊\" in (soup2.select(\".article-meta-value\")[2].text):\n",
    "                    pass\n",
    "                else:\n",
    "                    print(\"--------------------------------------------------------------------------------------------------\")\n",
    "                    soup3 = soup2.select(\".bbs-screen.bbs-content\")[0].text\n",
    "                    content =soup3.split(\"※\") and soup3.split(\"--\")\n",
    "                    content2 = content[0].split(\"2016\")\n",
    "                    print(content2[1])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def get_reply():\n",
    "    for i in range(a,b):\n",
    "        res = requests.get(\"https://www.ptt.cc/bbs/prozac/index\"+str(i)+\".html\")\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        for website in soup.select(\".r-ent\"):\n",
    "            try:    \n",
    "                res2 = requests.get('https://www.ptt.cc/'+website(\"a\")[0]['href'])\n",
    "                soup2 = BeautifulSoup(res2.text)\n",
    "                if \"資訊\" in (soup2.select(\".article-meta-value\")[2].text):\n",
    "                    pass\n",
    "                else:\n",
    "                    print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#                     推，箭頭，噓\n",
    "                    for i in range(len(soup2.select(\".push\"))):\n",
    "                        print(soup2.select(\".push-tag\")[i].text)\n",
    "#                     推文者ID\n",
    "                    for i in range(len(soup2.select(\".push\"))):\n",
    "                        print(soup2.select(\".push-userid\")[i].text)\n",
    "#                     推文內容\n",
    "                    for i in range(len(soup2.select(\".push\"))):\n",
    "                        print(soup2.select(\".push-content\")[i].text)\n",
    "#                     推文時間\n",
    "                    for i in range(len(soup2.select(\".push\"))):\n",
    "                        print(soup2.select(\".push-ipdatetime\")[i].text)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "print(get_title())\n",
    "print(get_author())\n",
    "# print(get_time())\n",
    "# print(get_content())\n",
    "# print(get_reply())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
